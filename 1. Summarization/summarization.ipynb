{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一. 文本总结(Summarization)\n",
    "\n",
    "- 扔给LLM一段文本，让他给你生成总结可以说是最常见的场景之一了\n",
    "- 目前最火的应用应该是 chatPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 短文本总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 config.py 中加载秘钥等配置\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from models import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summaries Of Short Text\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "llm = OpenAI(temperature=0, model_name = \"text-davinci-003\", openai_api_key=OPENAI_API_KEY) # 初始化LLM模型\n",
    "\n",
    "# 创建模板\n",
    "template = \"\"\"\n",
    "%INSTRUCTIONS:\n",
    "Please summarize the following piece of text.\n",
    "Respond in a manner that a 5 year old would understand.\n",
    "\n",
    "%TEXT:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# 创建一个 Lang Chain Prompt 模板，稍后可以插入值\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = \"\"\"\n",
    "For the next 130 years, debate raged.\n",
    "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
    "“The problem is that when you look up close at the anatomy, it’s evocative of a lot of different things, but it’s diagnostic of nothing,” says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
    "“And it’s so damn big that when whenever someone says it’s something, everyone else’s hackles get up: ‘How could you have a lichen 20 feet tall?’”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Prompt Begin -------\n",
      "\n",
      "%INSTRUCTIONS:\n",
      "Please summarize the following piece of text.\n",
      "Respond in a manner that a 5 year old would understand.\n",
      "\n",
      "%TEXT:\n",
      "\n",
      "For the next 130 years, debate raged.\n",
      "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
      "“The problem is that when you look up close at the anatomy, it’s evocative of a lot of different things, but it’s diagnostic of nothing,” says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
      "“And it’s so damn big that when whenever someone says it’s something, everyone else’s hackles get up: ‘How could you have a lichen 20 feet tall?’”\n",
      "\n",
      "\n",
      "------- Prompt End -------\n"
     ]
    }
   ],
   "source": [
    "print (\"------- Prompt Begin -------\")\n",
    "# 打印模板内容\n",
    "final_prompt = prompt.format(text=long_text)\n",
    "print(final_prompt)\n",
    "\n",
    "print (\"------- Prompt End -------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 130 years, people argued about what Prototaxites was. Some thought it was a lichen, some thought it was a fungus, and some thought it was a tree. But no one could agree. It was so big that it was hard to figure out what it was.\n"
     ]
    }
   ],
   "source": [
    "output = llm(final_prompt)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 长文本总结\n",
    "\n",
    "- 对于文本长度较短的文本我们可以直接这样执行summary操作\n",
    "- 但是对于文本长度超过lLM支持的max token size 时将会遇到困难，gpt-3.5 max token： https://platform.openai.com/docs/models/gpt-3-5\n",
    "- Lang Chain 提供了开箱即用的工具解决长文本的问题：load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries Of Longer Text\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1 Down the Rabbit-Hole\n",
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' th\n"
     ]
    }
   ],
   "source": [
    "with open('../data/alice_in_wonderland.txt', 'r') as file:\n",
    "    text = file.read() # 文章本身是爱丽丝梦游仙境\n",
    "\n",
    "# 打印小说的前285个字符\n",
    "print (text[:285])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken # 安装用于分割文本的依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25927 tokens in your file, file_size: 104171\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(text)\n",
    "\n",
    "print (f\"There are {num_tokens} tokens in your file, file_size: {text.__len__()}\") \n",
    "# 全文一共2w6词\n",
    "# 很明显这样的文本量是无法直接送进LLM进行处理和生成的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You now have 18 docs intead of 1 piece of text\n",
      "30\n",
      "11173\n",
      "27\n",
      "10835\n",
      "39\n",
      "9050\n",
      "43\n",
      "13760\n",
      "35\n",
      "11594\n",
      "24\n",
      "13636\n",
      "25\n",
      "12438\n",
      "32\n",
      "11209\n",
      "31\n",
      "10181\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=5000, chunk_overlap=350)\n",
    "# 虽然我使用的是 RecursiveCharacterTextSplitter，但是你也可以使用其他工具\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "#docs_size = [doc.page_content.__len__() for doc in docs]\n",
    "\n",
    "print (f\"You now have {len(docs)} docs intead of 1 piece of text\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 lang chain\n",
    "# 使用 map_reduce的chain_type，这样可以将多个文档合并成一个\n",
    "chain = load_summarize_chain(llm=llm, chain_type='map_reduce') # verbose=True 展示运行日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In Alice's Adventures in Wonderland, Alice follows a White Rabbit down a rabbit hole and finds herself in a surreal world. She meets a variety of strange creatures and has a series of bizarre adventures as she attempts to find her way home. Along the way, she encounters a Caterpillar, a Pigeon, a talking pig, and a pepper shaker, and attends a mad tea-party with the Mad Hatter, the March Hare, and the Dormouse. Eventually, she is brought to the court of the King and Queen of Hearts, where the White Rabbit reveals that the Knave of Hearts is the one who stole the tarts. Alice is released and the Knave is brought to trial.\n"
     ]
    }
   ],
   "source": [
    "# Use it. This will run through the 36 documents, summarize the chunks, then get a summary of the summary.\n",
    "# 典型的map reduce的思路去解决问题，将文章拆分成多个部分，再将多个部分分别进行 summarize，最后再进行 合并，对多个 summary 进行 summary\n",
    "output = chain.run(docs)\n",
    "print (output)\n",
    "# Try yourself"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
